https://arxiv.org/abs/2005.14165 提出少量样本学习的概率
## 少量样本学习（few-shot）
### 1. 定义
使用示例输入和预期输出，让模型知道我需要他做什么

也有其他的比如:  
zero-shot :不给示例  
one-shot : 给一个示例，为了学习格式和任务类型  
few-shot: 给多个示例   
fine-tune : 直接微调模型 

**在使用few-shot的过程中应该应该考虑** :  
1. 样例是怎么生成的
2. 每个prompt中有多少个样例合适
3. 怎么在运行时选择示例
4. prompt中示例是怎么格式化的

### 生成示例 
好的例子在运行时应该是相关的，清晰的，有信息量的，并且提供模型还不知道的信息。
1. 生成示例的基本方法有:
 - Manual:人自己觉得有用的示例
 - better: 用更好的模型生成的示例
 - User feedback: ： 用户的反馈转换成示例
 - LLM feedback : 模型自行评估自己的回答质量，比如：一个LLM生成回答后，再由另外一个或者同一个LLM判断是否准确  
方法的选择取决与具体需求，好理解的任务手工制作示例比较好（情感分类，单论问答，文本改写），  
对于正确行为空间更广泛、也更细微的任务比如多轮对话，医学咨询问答，法律判断，推理等**没有单一的“正确答案”，一个手工示例不能覆盖全部情况，多样化的输入**的情况自动生成采用LLM feedback更好

2. 示例的分类 single-turn 和 multi-turn
- single-turn : 用户给出的只有示例输入和预期输出

    ``` 
    你是一名医学助手，请判断以下症状描述属于哪个症状类型（头痛、咳嗽、腹痛、其他）。
    
    示例：
    症状描述：我的头痛一整天了，尤其在额头附近。
    症状类型：头痛
    
    症状描述：我喉咙痒，还一直咳嗽。
    症状类型：咳嗽
    ```
- multi-turn : 用户示例是整个对话，通常模型最初响应不正确，然后用户告诉模型如何纠正其答案。这称为多匝示例。多轮示例对于更细微的任务非常有用，在这些任务中，显示常见错误并准确说明它们错误的原因以及应该做什么非常有用。   
**数据来源** ： 1. 模型批量生成，再用另外一个模型筛选高质量示例 2. 有用户根据生成的文本进行返回，提取反馈结果加入示例中
**案例**    ：  
这是用户给的反馈
  ```
  {
    "user_input": "我最近总是胸闷气短，是不是心脏出问题了？",
    "ai_output": "胸闷气短的原因有很多，包括心脏病、焦虑、肺部问题等。建议您尽快就医，做个心电图或胸片检查。",
    "user_feedback": "👍"
  }
  ```
llm自动生成的流程
  ```
  1. 让模型自己批量生成任务示例
  2. 用 prompt：“请给出关于XXX任务的10组问答示例”
  可生成单轮或多轮对话
  3. 再调用另一个 LLM 执行“质量评估”
  例如 prompt：“以下示例是否逻辑正确、语言通顺、有帮助？”
  输出 Yes / No 或 评分
  4.筛选得分高的样本保存
  ```

### 示例的选择 
一般通过语义相似性进行选择，也有随机和其他方法，比如 token的大小（后续使用再仔细讨论，一般现在好的模型使用的示例更少）

### 示例的格式
模型不同，要求不同


根据链接 https://blog.langchain.com/few-shot-prompting-to-improve-tool-calling-performance/  的实验结果发现：`使用基于语义相似度动态选择示例，并且使用消息列表的形似插入系统和用户对话之间效果更好`  

示例选择器的大概类型:
1. **Similarity**：基于输入与示例之间的语义相似度来选择示例。这种方法通过比较语义内容的接近程度来确定最相关的示例。

2. **MMR (Maximum Margin Relevance)：**根据输入与示例之间的最大边际相关性来挑选示例。这种方法旨在平衡相关性和多样性，通过选择既相关又能提供新信息的示例。

3. **Length**：依据指定长度内能够容纳的示例数量来进行选择。这个方法简单直接，特别适用于需要控制输出长度的场景。

4. **Ngram**：通过计算输入与示例之间的n-gram重叠来选择示例。这种方法重视文本表面的匹配度，适用于需要精确文本匹配的情境。

Similarity的示例参照 `5.动态few-shot`
