from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from langchain.chat_models import init_chat_model
from langchain_core.runnables import ConfigurableFieldSpec

# åˆå§‹åŒ–æ¨¡å‹
llm = init_chat_model(
    model="deepseek-r1:7b-qwen-distill-q4_K_M",
    base_url="http://localhost:11434",
    model_provider="ollama"
)

# prompt æ¨¡æ¿
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯æœºå™¨äºº {bot_name}"),
    MessagesPlaceholder("history"),
    ("human", "{input}"),
])

chain = prompt | llm

# å†å²å­˜å‚¨
store = {}


def get_history(user_id, conversation_id, bot_name):
    key = f"{user_id}_{conversation_id}_{bot_name}"
    if key not in store:
        store[key] = InMemoryChatMessageHistory()
    return store[key]


# ğŸ”¹ æ¶ˆæ¯è£å‰ª + æ‘˜è¦ç”Ÿæˆ
def trim_and_summarize(history: InMemoryChatMessageHistory, max_full_messages=3):
    """
    - ä¿ç•™æœ€è¿‘ max_full_messages æ¡å®Œæ•´æ¶ˆæ¯
    - æ—§æ¶ˆæ¯ç”Ÿæˆæ‘˜è¦æ›¿ä»£
    """
    messages = history.messages
    if len(messages) <= max_full_messages:
        return history

    old_messages = messages[:-max_full_messages]
    new_messages = messages[-max_full_messages:]

    # å°†æ—§æ¶ˆæ¯åˆå¹¶æˆæ‘˜è¦
    old_text = "\n".join([f"{m.type}: {m.content}" for m in old_messages])
    summary_prompt = f"""ä½ æ˜¯ä¸€åå¯¹è¯æ‘˜è¦åŠ©æ‰‹ï¼Œè¯·å°†ä»¥ä¸‹å†å²å¯¹è¯å‹ç¼©æˆä¸€å¥è¯æˆ–å‡ å¥è¯ï¼Œä¿ç•™é‡è¦ä¿¡æ¯å¹¶åˆ é™¤å†—ä½™å†…å®¹ã€‚
å¯¹è¯å†å²ï¼š
{old_text}
è¯·ç”¨ç®€æ´è‡ªç„¶çš„è¯­è¨€æ€»ç»“ä¸Šé¢å¯¹è¯çš„æ ¸å¿ƒå†…å®¹ï¼š"""

    summary_content = llm.invoke(summary_prompt)
        # llm([HumanMessage(content=summary_prompt)]).content

    # ç”¨æ‘˜è¦æ›¿æ¢æ—§æ¶ˆæ¯
    summary_message = AIMessage(content=f"[å†å²æ‘˜è¦] {summary_content}")
    history.messages = [summary_message] + new_messages


# åŒ…è£… RunnableWithMessageHistoryï¼Œè‡ªåŠ¨è£å‰ª
def make_chain(bot_name):
    return RunnableWithMessageHistory(
        chain,
        get_session_history=get_history,
        input_messages_key="input",
        history_messages_key="history",
        history_factory_config=[
            ConfigurableFieldSpec(id="user_id", annotation=str, default="u1"),
            ConfigurableFieldSpec(id="conversation_id", annotation=str, default="c1"),
            ConfigurableFieldSpec(id="bot_name", annotation=str, default=bot_name),
        ]
    )


# ç¤ºä¾‹
chain_a = make_chain("A")

# æ¨¡æ‹Ÿå¯¹è¯
history_a = get_history("u1", "c1", "A")
for user_input in ["ä½ å¥½", "æˆ‘ä»Šå¤©å¿ƒæƒ…ä¸å¥½", "å·¥ä½œå‹åŠ›å¾ˆå¤§", "æœ‰ä»€ä¹ˆç¼“è§£æ–¹æ³•ï¼Ÿ"]:
    trim_and_summarize(history_a, max_full_messages=2)  # ä¿ç•™æœ€è¿‘ 2 æ¡å®Œæ•´æ¶ˆæ¯ï¼Œå…¶ä½™æ‘˜è¦åŒ–
    res = chain_a.invoke({"input": user_input, "bot_name": "A"}, config={
        "configurable": {"user_id": "u1", "conversation_id": "c1", "bot_name": "A"}
    })
    print(res.content)

# æŸ¥çœ‹è£å‰ªåå†å²
for msg in history_a.messages:
    print(f"{msg.type}: {msg.content}")
